{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import argparse\n",
    "import repackage\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_utils import set_env, seed_everything\n",
    "set_env()\n",
    "from cgn_framework.mnists.generate_data import generate_cf_dataset, generate_dataset, get_dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train concept classifier for double-colored-MNIST\n",
    "We need to train:\n",
    "1. A CF for classifying the digit's color\n",
    "2. A CF for classifying the digit's shape\n",
    "3. A CF for background color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train, dl_test = get_dataloaders('double_colored_MNIST', batch_size=1000, workers=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 50000\n",
      "Test: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {dl_train.dataset.labels.shape[0]}\")\n",
    "print(f\"Test: {dl_test.dataset.labels.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.randint(0, dl_train.dataset.labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "ename": "KeyError",
     "evalue": "'bg_label'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m/home/lcur1334/dl2-cgn/concepts_experiments/double_colored_MNIST_cf.ipynb Cell 10'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/lcur1334/dl2-cgn/concepts_experiments/double_colored_MNIST_cf.ipynb#ch0000008vscode-remote?line=2'>3</a>\u001b[0m plt\u001b[39m.\u001b[39mtitle(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mDigit: \u001b[39m\u001b[39m{\u001b[39;00mlabel\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/lcur1334/dl2-cgn/concepts_experiments/double_colored_MNIST_cf.ipynb#ch0000008vscode-remote?line=3'>4</a>\u001b[0m plt\u001b[39m.\u001b[39mshow()\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/lcur1334/dl2-cgn/concepts_experiments/double_colored_MNIST_cf.ipynb#ch0000008vscode-remote?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mBG label: \u001b[39m\u001b[39m{\u001b[39;00m(dl_train\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(random_idx)[\u001b[39m'\u001b[39m\u001b[39mbg_label\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m255\u001b[39m)\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/lcur1334/dl2-cgn/concepts_experiments/double_colored_MNIST_cf.ipynb#ch0000008vscode-remote?line=5'>6</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mTexture label: \u001b[39m\u001b[39m{\u001b[39;00m(dl_train\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m\u001b[39m__getitem__\u001b[39m(random_idx)[\u001b[39m'\u001b[39m\u001b[39mtexture_label\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m*\u001b[39m\u001b[39m255\u001b[39m)\u001b[39m.\u001b[39mtolist()\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n",
      "\u001b[0;31mKeyError\u001b[0m: 'bg_label'"
     ]
    }
   ],
   "source": [
    "plt.imshow(dl_train.dataset.__getitem__(random_idx)['ims'].transpose(0,1).transpose(1,2))\n",
    "label = dl_train.dataset.__getitem__(random_idx)['labels']\n",
    "plt.title(f\"Digit: {label}\")\n",
    "plt.show()\n",
    "print(f\"BG label: {(dl_train.dataset.__getitem__(random_idx)['bg_label']*255).tolist()}\")\n",
    "print(f\"Texture label: {(dl_train.dataset.__getitem__(random_idx)['texture_label']*255).tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train color CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from cgn_framework.mnists.models.classifier import CNN\n",
    "from train_classifier import train, test\n",
    "\n",
    "# Args for training\n",
    "args = argparse.Namespace()\n",
    "args.batch_size = 1000\n",
    "args.gamma = 0.7\n",
    "args.epochs = 10\n",
    "args.lr = 1.0\n",
    "args.log_interval = 100\n",
    "args.dataset = 'double_colored_MNIST'\n",
    "\n",
    "# Data\n",
    "dl_train, dl_test = get_dataloaders(args.dataset, batch_size=args.batch_size, workers=8)\n",
    "\n",
    "# Model\n",
    "model = CNN()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "\n",
    "# push to device and train\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/50000 (0%)]\tLoss: 2.302454\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/home/lcur1334/dl2-cgn/concepts_experiments/double_colored_MNIST_cf.ipynb Cell 13'\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/lcur1334/dl2-cgn/concepts_experiments/double_colored_MNIST_cf.ipynb#ch0000020vscode-remote?line=1'>2</a>\u001b[0m test_accs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m()\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/lcur1334/dl2-cgn/concepts_experiments/double_colored_MNIST_cf.ipynb#ch0000020vscode-remote?line=2'>3</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, args\u001b[39m.\u001b[39mepochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/lcur1334/dl2-cgn/concepts_experiments/double_colored_MNIST_cf.ipynb#ch0000020vscode-remote?line=3'>4</a>\u001b[0m     train_acc \u001b[39m=\u001b[39m train(args, model, device, dl_train, optimizer, epoch)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/lcur1334/dl2-cgn/concepts_experiments/double_colored_MNIST_cf.ipynb#ch0000020vscode-remote?line=4'>5</a>\u001b[0m     test_acc \u001b[39m=\u001b[39m test(model, device, dl_test)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Blisa.surfsara.nl/home/lcur1334/dl2-cgn/concepts_experiments/double_colored_MNIST_cf.ipynb#ch0000020vscode-remote?line=5'>6</a>\u001b[0m     train_accs[epoch] \u001b[39m=\u001b[39m train_acc\n",
      "File \u001b[0;32m~/dl2-cgn/concepts_experiments/train_classifier.py:26\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(args, model, device, train_loader, optimizer, epoch)\u001b[0m\n\u001b[1;32m     <a href='file:///home/lcur1334/dl2-cgn/concepts_experiments/train_classifier.py?line=23'>24</a>\u001b[0m data, target \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mto(device), target\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='file:///home/lcur1334/dl2-cgn/concepts_experiments/train_classifier.py?line=24'>25</a>\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[0;32m---> <a href='file:///home/lcur1334/dl2-cgn/concepts_experiments/train_classifier.py?line=25'>26</a>\u001b[0m output \u001b[39m=\u001b[39m model(data)\n\u001b[1;32m     <a href='file:///home/lcur1334/dl2-cgn/concepts_experiments/train_classifier.py?line=26'>27</a>\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mnll_loss(output, target)\n\u001b[1;32m     <a href='file:///home/lcur1334/dl2-cgn/concepts_experiments/train_classifier.py?line=27'>28</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/dl2-cgn/cgn_framework/mnists/models/classifier.py:40\u001b[0m, in \u001b[0;36mCNN.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     <a href='file:///home/lcur1334/dl2-cgn/cgn_framework/mnists/models/classifier.py?line=38'>39</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, x):\n\u001b[0;32m---> <a href='file:///home/lcur1334/dl2-cgn/cgn_framework/mnists/models/classifier.py?line=39'>40</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcls(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel(x))\n",
      "File \u001b[0;32m~/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/container.py:141\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/container.py?line=138'>139</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m):\n\u001b[1;32m    <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/container.py?line=139'>140</a>\u001b[0m     \u001b[39mfor\u001b[39;00m module \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m:\n\u001b[0;32m--> <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/container.py?line=140'>141</a>\u001b[0m         \u001b[39minput\u001b[39m \u001b[39m=\u001b[39m module(\u001b[39minput\u001b[39;49m)\n\u001b[1;32m    <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/container.py?line=141'>142</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39minput\u001b[39m\n",
      "File \u001b[0;32m~/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py:1102\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1097'>1098</a>\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1098'>1099</a>\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1099'>1100</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1100'>1101</a>\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1101'>1102</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49m\u001b[39minput\u001b[39;49m, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1102'>1103</a>\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/module.py?line=1103'>1104</a>\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/conv.py:446\u001b[0m, in \u001b[0;36mConv2d.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=444'>445</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=445'>446</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_conv_forward(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "File \u001b[0;32m~/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/conv.py:442\u001b[0m, in \u001b[0;36mConv2d._conv_forward\u001b[0;34m(self, input, weight, bias)\u001b[0m\n\u001b[1;32m    <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=437'>438</a>\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode \u001b[39m!=\u001b[39m \u001b[39m'\u001b[39m\u001b[39mzeros\u001b[39m\u001b[39m'\u001b[39m:\n\u001b[1;32m    <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=438'>439</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39mconv2d(F\u001b[39m.\u001b[39mpad(\u001b[39minput\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reversed_padding_repeated_twice, mode\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpadding_mode),\n\u001b[1;32m    <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=439'>440</a>\u001b[0m                     weight, bias, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=440'>441</a>\u001b[0m                     _pair(\u001b[39m0\u001b[39m), \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdilation, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mgroups)\n\u001b[0;32m--> <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=441'>442</a>\u001b[0m \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mconv2d(\u001b[39minput\u001b[39;49m, weight, bias, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride,\n\u001b[1;32m    <a href='file:///home/lcur1334/.conda/envs/cgn-gpu/lib/python3.9/site-packages/torch/nn/modules/conv.py?line=442'>443</a>\u001b[0m                 \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_accs = dict()\n",
    "test_accs = dict()\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train_acc = train(args, model, device, dl_train, optimizer, epoch)\n",
    "    test_acc = test(model, device, dl_test)\n",
    "    train_accs[epoch] = train_acc\n",
    "    test_accs[epoch] = test_acc\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train shape CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train background CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2cd83209aa77ccc6cda195793ce85b2396716d6b33506ed3886cd902c3fd47b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('cgn-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
