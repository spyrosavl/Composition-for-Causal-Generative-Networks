{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import argparse\n",
    "import repackage\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms\n",
    "from torch.optim.lr_scheduler import StepLR\n",
    "\n",
    "# from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
    "# from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
    "# from pytorch_grad_cam.utils.image import show_cam_on_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from experiment_utils import set_env, seed_everything\n",
    "set_env()\n",
    "from cgn_extensions.mnists.dataloaders import get_dataloaders"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train concept classifier for double-colored-MNIST\n",
    "We need to train:\n",
    "1. A CF for classifying the digit's color\n",
    "2. A CF for classifying the digit's shape\n",
    "3. A CF for background color"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "dl_train, dl_test = get_dataloaders('double_colored_MNIST', batch_size=1000, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 10000\n",
      "Test: 10000\n"
     ]
    }
   ],
   "source": [
    "print(f\"Train: {dl_train.dataset.labels.shape[0]}\")\n",
    "print(f\"Test: {dl_test.dataset.labels.shape[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get a sample image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "random_idx = np.random.randint(0, dl_train.dataset.labels.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BG label: tensor([0])\n",
      "Texture label: tensor([6])\n"
     ]
    }
   ],
   "source": [
    "plt.imshow(dl_train.dataset.__getitem__(random_idx)['ims'].transpose(0,1).transpose(1,2))\n",
    "label = dl_train.dataset.__getitem__(random_idx)['labels']\n",
    "plt.title(f\"Digit: {label}\")\n",
    "plt.show()\n",
    "print(f\"BG label: {dl_train.dataset.__getitem__(random_idx)['bg_labels']}\")\n",
    "print(f\"Texture label: {dl_train.dataset.__getitem__(random_idx)['texture_labels']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train color CF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from cgn_extensions.mnists.models.mnist_color_cf import train, test, MNIST_COLOR_CNN\n",
    "\n",
    "# Args for training\n",
    "args = argparse.Namespace()\n",
    "args.batch_size = 512\n",
    "args.gamma = 0.7\n",
    "args.epochs = 10\n",
    "args.lr = 0.01\n",
    "args.log_interval = 10\n",
    "args.dataset = 'double_colored_MNIST'\n",
    "\n",
    "# Data\n",
    "dl_train, dl_test = get_dataloaders(args.dataset, batch_size=args.batch_size, workers=4)\n",
    "\n",
    "# Model\n",
    "model = MNIST_COLOR_CNN(num_classes=10)\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.Adadelta(model.parameters(), lr=args.lr)\n",
    "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
    "\n",
    "# push to device and train\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/10000 (0%)]\tLoss: 2.102597\n",
      "Train Epoch: 1 [5120/10000 (50%)]\tLoss: 2.043093\n",
      "\n",
      "Train set: Average loss: 1.9928, Accuracy: 3328/10000 (33.3%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.9916, Accuracy: 3867/10000 (38.670%)\n",
      "\n",
      "Train Epoch: 2 [0/10000 (0%)]\tLoss: 1.988478\n",
      "Train Epoch: 2 [5120/10000 (50%)]\tLoss: 1.963446\n",
      "\n",
      "Train set: Average loss: 1.9377, Accuracy: 4096/10000 (41.0%)\n",
      "\n",
      "\n",
      "Test set: Average loss: 1.9303, Accuracy: 4579/10000 (45.790%)\n",
      "\n",
      "Train Epoch: 3 [0/10000 (0%)]\tLoss: 1.940030\n",
      "Train Epoch: 3 [5120/10000 (50%)]\tLoss: 1.909683\n",
      "\n",
      "Train set: Average loss: 1.8657, Accuracy: 4776/10000 (47.8%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_accs = dict()\n",
    "test_accs = dict()\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train_acc = train(args, model, device, dl_train, optimizer, epoch, 'texture', max_batches=200)\n",
    "    test_acc = test(model, device, dl_test, 'texture')\n",
    "    train_accs[epoch] = train_acc\n",
    "    test_accs[epoch] = test_acc\n",
    "    scheduler.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot losses\n",
    "plt.plot(train_accs.keys(), train_accs.values())\n",
    "plt.plot(test_accs.keys(), test_accs.values())\n",
    "plt.legend(['train', 'test'])\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GradCam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target layer for Grad-CAM\n",
    "target_layers = [model.model[3]]\n",
    "\n",
    "# Construct the CAM object once, and then re-use it on many images:\n",
    "cam = GradCAM(model=model, target_layers=target_layers, use_cuda=torch.cuda.is_available())\n",
    "\n",
    "# Get a random batch\n",
    "dl_train, dl_test = get_dataloaders('double_colored_MNIST', batch_size=10, workers=4)\n",
    "gradcam_data = next(iter(dl_train))\n",
    "input_tensor = gradcam_data['ims'][0].unsqueeze(0).clip(min=0, max=1).to(device)\n",
    "grayscale_cam = cam(input_tensor=input_tensor, targets=None)\n",
    "grayscale_cam = grayscale_cam[0, :]\n",
    "\n",
    "rgb_img = input_tensor.squeeze(0).transpose(0,1).transpose(1,2).to('cpu').detach().numpy()\n",
    "visualization = show_cam_on_image(rgb_img, grayscale_cam, use_rgb=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(rgb_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(visualization)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # save the model\n",
    "# dataset_suffix = (args.dataset) if not args.combined else (args.dataset + \"_combined\")\n",
    "# dataset_suffix += \"_seed_\" + str(args.seed) if args.seed is not None else \"\"\n",
    "# save_path = f'mnists/experiments/classifier_{dataset_suffix}/weights/ckp_epoch_{args.epochs}.pth'\n",
    "# os.makedirs(os.path.dirname(save_path), exist_ok=True)\n",
    "# print('Saving model to {}'.format(save_path))\n",
    "# torch.save(model.state_dict(), save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make some predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train shape CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train background CF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "7d28fd230918e024941f72fd9a5ff2bb0ca9d4bf408677d1aa8413c38ad123b1"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('cgn-cpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
