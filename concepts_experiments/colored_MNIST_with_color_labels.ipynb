{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The original colored MNIST dataset does not have color labels. We need to create a new dataset with color labels.\n",
    "\n",
    "\n",
    "We define three environments (two training, one test) by randomly splitting the MNIST dataset in thirds and transforming each example as follows:\n",
    "1. Assign a binary label y to the image based on the digit: y = 0 for digits 0-4\n",
    "and y = 1 for digits 5-9.\n",
    "2. Flip the label with 25% probability.\n",
    "3. Color the image either red or green according to its (possibly flipped) label.\n",
    "4. Flip the color with a probability e that depends on the environment: 20% in\n",
    "the first training environment, 10% in the second training environment, and\n",
    "90% in the test environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def color_grayscale_arr(arr, red=True):\n",
    "  \"\"\"Converts grayscale image to either red or green\"\"\"\n",
    "  assert arr.ndim == 2\n",
    "  dtype = arr.dtype\n",
    "  h, w = arr.shape\n",
    "  arr = np.reshape(arr, [h, w, 1])\n",
    "  if red:\n",
    "    arr = np.concatenate([arr,\n",
    "                          np.zeros((h, w, 2), dtype=dtype)], axis=2)\n",
    "  else:\n",
    "    arr = np.concatenate([np.zeros((h, w, 1), dtype=dtype),\n",
    "                          arr,\n",
    "                          np.zeros((h, w, 1), dtype=dtype)], axis=2)\n",
    "  return arr\n",
    "\n",
    "\n",
    "class ColoredMNIST(datasets.VisionDataset):\n",
    "  \"\"\"\n",
    "  Colored MNIST dataset for testing IRM. Prepared using procedure from https://arxiv.org/pdf/1907.02893.pdf\n",
    "\n",
    "  Args:\n",
    "    root (string): Root directory of dataset where ``ColoredMNIST/*.pt`` will exist.\n",
    "    env (string): Which environment to load. Must be 1 of 'train1', 'train2', 'test', or 'all_train'.\n",
    "    transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "      and returns a transformed version. E.g, ``transforms.RandomCrop``\n",
    "    target_transform (callable, optional): A function/transform that takes in the\n",
    "      target and transforms it.\n",
    "  \"\"\"\n",
    "  def __init__(self, root='./data', env='train1', transform=None, target_transform=None):\n",
    "    super(ColoredMNIST, self).__init__(root, transform=transform,\n",
    "                                target_transform=target_transform)\n",
    "\n",
    "    self.prepare_colored_mnist()\n",
    "    if env in ['train', 'test']:\n",
    "      self.data_label_tuples = torch.load(os.path.join(self.root, 'ColoredMNIST', env) + '.pt')\n",
    "    elif env == 'all_train':\n",
    "      self.data_label_tuples = torch.load(os.path.join(self.root, 'ColoredMNIST', 'train1.pt')) + \\\n",
    "                               torch.load(os.path.join(self.root, 'ColoredMNIST', 'train2.pt'))\n",
    "    else:\n",
    "      raise RuntimeError(f'{env} env unknown. Valid envs are train1, train2, test, and all_train')\n",
    "\n",
    "  def __getitem__(self, index):\n",
    "    \"\"\"\n",
    "    Args:\n",
    "        index (int): Index\n",
    "\n",
    "    Returns:\n",
    "        tuple: (image, target) where target is index of the target class.\n",
    "    \"\"\"\n",
    "    img, target = self.data_label_tuples[index]\n",
    "\n",
    "    if self.transform is not None:\n",
    "      img = self.transform(img)\n",
    "\n",
    "    if self.target_transform is not None:\n",
    "      target = self.target_transform(target)\n",
    "\n",
    "    return img, target\n",
    "\n",
    "  def __len__(self):\n",
    "    return len(self.data_label_tuples)\n",
    "\n",
    "  def prepare_colored_mnist(self):\n",
    "    colored_mnist_dir = os.path.join(self.root, 'ColoredMNIST')\n",
    "    if os.path.exists(os.path.join(colored_mnist_dir, 'train1.pt')) \\\n",
    "        and os.path.exists(os.path.join(colored_mnist_dir, 'train2.pt')) \\\n",
    "        and os.path.exists(os.path.join(colored_mnist_dir, 'test.pt')):\n",
    "      print('Colored MNIST dataset already exists')\n",
    "      return\n",
    "\n",
    "    print('Preparing Colored MNIST')\n",
    "    train_mnist = datasets.mnist.MNIST(self.root, train=True, download=True)\n",
    "\n",
    "    train1_set = []\n",
    "    train2_set = []\n",
    "    test_set = []\n",
    "    for idx, (im, label) in enumerate(train_mnist):\n",
    "      if idx % 10000 == 0:\n",
    "        print(f'Converting image {idx}/{len(train_mnist)}')\n",
    "      im_array = np.array(im)\n",
    "\n",
    "      # Assign a binary label y to the image based on the digit\n",
    "      binary_label = 0 if label < 5 else 1\n",
    "\n",
    "      # Flip label with 25% probability\n",
    "      if np.random.uniform() < 0.25:\n",
    "        binary_label = binary_label ^ 1\n",
    "\n",
    "      # Color the image either red or green according to its possibly flipped label\n",
    "      color_red = binary_label == 0\n",
    "\n",
    "      # Flip the color with a probability e that depends on the environment\n",
    "      if idx < 20000:\n",
    "        # 20% in the first training environment\n",
    "        if np.random.uniform() < 0.2:\n",
    "          color_red = not color_red\n",
    "      elif idx < 40000:\n",
    "        # 10% in the first training environment\n",
    "        if np.random.uniform() < 0.1:\n",
    "          color_red = not color_red\n",
    "      else:\n",
    "        # 90% in the test environment\n",
    "        if np.random.uniform() < 0.9:\n",
    "          color_red = not color_red\n",
    "\n",
    "      colored_arr = color_grayscale_arr(im_array, red=color_red)\n",
    "\n",
    "      if idx < 20000:\n",
    "        train1_set.append((Image.fromarray(colored_arr), binary_label))\n",
    "      elif idx < 40000:\n",
    "        train2_set.append((Image.fromarray(colored_arr), binary_label))\n",
    "      else:\n",
    "        test_set.append((Image.fromarray(colored_arr), binary_label))\n",
    "\n",
    "      # Debug\n",
    "      # print('original label', type(label), label)\n",
    "      # print('binary label', binary_label)\n",
    "      # print('assigned color', 'red' if color_red else 'green')\n",
    "      # plt.imshow(colored_arr)\n",
    "      # plt.show()\n",
    "      # break\n",
    "\n",
    "    dataset_utils.makedir_exist_ok(colored_mnist_dir)\n",
    "    torch.save(train1_set, os.path.join(colored_mnist_dir, 'train1.pt'))\n",
    "    torch.save(train2_set, os.path.join(colored_mnist_dir, 'train2.pt'))\n",
    "    torch.save(test_set, os.path.join(colored_mnist_dir, 'test.pt'))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c2cd83209aa77ccc6cda195793ce85b2396716d6b33506ed3886cd902c3fd47b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('cgn-gpu')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
